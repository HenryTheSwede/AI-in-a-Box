{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Financial Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "\n",
    "- This notebook integrates an Assistant employing two tools: Function Calling and Code Interpreter. Leveraging a CSV file containing the user's investment portfolio, the system fetches real-time stock prices via ticker symbols using Function Calling. It conducts calculations through Code Interpreter and subsequently sends a report to the user via email using Function Calling\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://aka.ms/oai/access)\n",
    "- Azure OpenAI service - you can create it from instructions [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource)\n",
    "- Azure OpenAI Studio - go to [https://oai.azure.com/](https://oai.azure.com/) to work with the Assistants API Playground\n",
    "- A connection to the Azure OpenAI Service with a [Key and Endpoint](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart)\n",
    "\n",
    "Reference:\n",
    "- Learn more about how to use Assistants with our [How-to guide on Assistants](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant)\n",
    "- [Assistants OpenAI Overview](https://platform.openai.com/docs/assistants/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 10-15 minutes running this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "This sample demonstrates the creation of an Azure OpenAI Assistant named \"Portfolio Management Assistant\" utilizing the Azure OpenAI API. The assistant is designed to act as a personal financial assistant, providing information and insights related to a user's investment portfolio. The script initiates a conversation with the assistant, guiding it through various financial queries and scenarios to showcase its capabilities.\n",
    "\n",
    "### Data\n",
    "This sample uses files from the folder [`data/`](./data/) in this repo. You can clone this repo or copy this folder to make sure you have access to these files when running the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.16.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (1.16.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.10.13/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: yfinance in /usr/local/python/3.10.13/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (0.2.40)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.10/site-packages (from -r ../requirements.txt (line 4)) (10.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (2.7.3)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai==1.16.2->-r ../requirements.txt (line 1)) (4.12.0)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/codespace/.local/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /home/codespace/.local/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (5.2.2)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (4.2.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in /home/codespace/.local/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (2.4.4)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (3.17.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/codespace/.local/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from yfinance->-r ../requirements.txt (line 3)) (1.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.16.2->-r ../requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.16.2->-r ../requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance->-r ../requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from html5lib>=1.1->yfinance->-r ../requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/codespace/.local/lib/python3.10/site-packages (from html5lib>=1.1->yfinance->-r ../requirements.txt (line 3)) (0.5.1)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.16.2->-r ../requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.16.2->-r ../requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.16.2->-r ../requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance->-r ../requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance->-r ../requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.16.2->-r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.16.2->-r ../requirements.txt (line 1)) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.31->yfinance->-r ../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.31->yfinance->-r ../requirements.txt (line 3)) (2.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")  # make sure to have the .env file in the root directory of the project\n",
    "\n",
    "api_endpoint = os.getenv(\"OPENAI_URI\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "api_deployment_name = os.getenv(\"OPENAI_GPT_DEPLOYMENT\")\n",
    "email_URI = os.getenv(\"EMAIL_URI\")\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import io\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from openai import AzureOpenAI\n",
    "from openai.types import FileObject\n",
    "from openai.types.beta import Thread\n",
    "from openai.types.beta.threads import Run\n",
    "from openai.types.beta.threads.text_content_block import TextContentBlock\n",
    "from openai.types.beta.threads.image_file_content_block import ImageFileContentBlock\n",
    "from openai.types.beta.threads.messages import MessageFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")  # make sure to have the .env file in the root directory of the project\n",
    "\n",
    "api_endpoint = os.getenv(\"OPENAI_URI\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "api_deployment_name = os.getenv(\"OPENAI_GPT_DEPLOYMENT\")\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the latest stock price by ticker symbol using Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol: str) -> float:\n",
    "    stock = yf.Ticker(symbol)\n",
    "    return stock.history(period=\"1d\")[\"Close\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send an email using Logic Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_logic_apps_email(to: str, content: str) -> None:\n",
    "    # In this demo email was implemented using a Logic App with an HTTP trigger and M365 email action\n",
    "    # Here are instructions on how to create an email endpoint using Logic Apps\n",
    "    #   https://learn.microsoft.com/en-us/azure/app-service/tutorial-send-email?tabs=python\n",
    "    try:\n",
    "        json_payload = {\"to\": to, \"content\": html.unescape(content)}\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        response = requests.post(email_URI, json=json_payload, headers=headers)\n",
    "        if response.status_code == 202:\n",
    "            print(\"Email sent to: \" + json_payload[\"to\"])\n",
    "    except:\n",
    "        print(\"Failed to send email via Logic Apps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Assistant tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [\n",
    "    {\"type\": \"code_interpreter\"},\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_stock_price\",\n",
    "            \"description\": \"Retrieve the latest closing price of a stock using its ticker symbol.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"The ticker symbol of the stock\"}},\n",
    "                \"required\": [\"symbol\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\n",
    "    #         \"name\": \"send_email\",\n",
    "    #         \"description\": \"Sends an email to a recipient(s).\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"to\": {\"type\": \"string\", \"description\": \"The email(s) the email should be sent to.\"},\n",
    "    #                 \"content\": {\"type\": \"string\", \"description\": \"The content of the email.\"},\n",
    "    #             },\n",
    "    #             \"required\": [\"to\", \"content\"],\n",
    "    #         },\n",
    "    #     },\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "\n",
    "def upload_file(client: AzureOpenAI, path: str) -> FileObject:\n",
    "    with Path(path).open(\"rb\") as f:\n",
    "        return client.files.create(file=f, purpose=\"assistants\")\n",
    "\n",
    "arr = os.listdir(DATA_FOLDER)\n",
    "assistant_files = []\n",
    "for file in arr:\n",
    "    filePath = DATA_FOLDER + file\n",
    "    assistant_files.append(upload_file(client, filePath))\n",
    "\n",
    "file_ids = [file.id for file in assistant_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Assistant and a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_deployment_name = \"gpt-4-turbo\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dall-e-3-3.0\n",
      "dall-e-2-2.0\n",
      "tts-001\n",
      "tts-hd-001\n",
      "whisper-001\n",
      "gpt-35-turbo-0301\n",
      "gpt-35-turbo-0613\n",
      "gpt-35-turbo-1106\n",
      "gpt-35-turbo-0125\n",
      "gpt-35-turbo-instruct-0914\n",
      "gpt-35-turbo-16k-0613\n",
      "gpt-4-0125-Preview\n",
      "gpt-4-1106-Preview\n",
      "gpt-4-0314\n",
      "gpt-4-0613\n",
      "gpt-4-32k-0314\n",
      "gpt-4-32k-0613\n",
      "gpt-4-vision-preview\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-jp\n",
      "gpt-4o-2024-05-13\n",
      "ada\n",
      "text-similarity-ada-001\n",
      "text-search-ada-doc-001\n",
      "text-search-ada-query-001\n",
      "code-search-ada-code-001\n",
      "code-search-ada-text-001\n",
      "text-embedding-ada-002\n",
      "text-embedding-ada-002-2\n",
      "babbage\n",
      "babbage-002\n",
      "text-similarity-babbage-001\n",
      "text-search-babbage-doc-001\n",
      "text-search-babbage-query-001\n",
      "code-search-babbage-code-001\n",
      "code-search-babbage-text-001\n",
      "curie\n",
      "text-similarity-curie-001\n",
      "text-search-curie-doc-001\n",
      "text-search-curie-query-001\n",
      "davinci\n",
      "davinci-002\n",
      "text-davinci-003\n",
      "text-similarity-davinci-001\n",
      "text-search-davinci-doc-001\n",
      "text-search-davinci-query-001\n",
      "text-embedding-3-small\n",
      "text-embedding-3-large\n",
      "dall-e-3\n",
      "dall-e-2\n",
      "tts\n",
      "tts-hd\n",
      "whisper\n",
      "gpt-35-turbo\n",
      "gpt-35-turbo-instruct\n",
      "gpt-35-turbo-16k\n",
      "gpt-4\n",
      "gpt-4-32k\n",
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "all_models = list(client.models.list())\n",
    "\n",
    "for model in all_models:\n",
    "    print(model.id)\n",
    "    print(model.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AzureOpenAI' object has no attribute 'deployments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_deployments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployments\u001b[49m\u001b[38;5;241m.\u001b[39mlist())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AzureOpenAI' object has no attribute 'deployments'"
     ]
    }
   ],
   "source": [
    "\n",
    "all_deployments = list(client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant-3ywGBInm1sL3No8NeRLAUi3n portfolio.csv assistants\n",
      "assistant-BVkNSQFYZ5uEWBydY0pIM4NU product_info_2.md assistants\n",
      "assistant-0z6jSAjxbgqzbG1RNH7JCx1Z product_info_1.md assistants\n"
     ]
    }
   ],
   "source": [
    "all_files = list(client.files.list())\n",
    "\n",
    "for file in all_files:\n",
    "    print(file.id, file.filename, file.purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Unknown parameter: 'file_ids'.\", 'type': 'invalid_request_error', 'param': 'file_ids', 'code': 'unknown_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m assistant \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massistants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPortfolio Management Assistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a personal securities trading assistant. Please be polite, professional, helpful, and friendly. \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUse the provided portfolio CSV file to answer the questions. If question is not related to the portfolio or you cannot answer the question, say, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontact a representative for more assistance.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIf the user asks for help or says \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhelp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, provide a list of sample questions that you can answer.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_deployment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m thread \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/resources/beta/assistants/assistants.py:112\u001b[0m, in \u001b[0;36mAssistants.create\u001b[0;34m(self, model, description, file_ids, instructions, metadata, name, tools, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mCreate an assistant with a model and instructions.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/assistants\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43massistant_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssistantCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAssistant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1212\u001b[0m     )\n\u001b[0;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    992\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    996\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    997\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1001\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Unknown parameter: 'file_ids'.\", 'type': 'invalid_request_error', 'param': 'file_ids', 'code': 'unknown_parameter'}}"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Portfolio Management Assistant\",\n",
    "    instructions=\"You are a personal securities trading assistant. Please be polite, professional, helpful, and friendly. \"\n",
    "    + \"Use the provided portfolio CSV file to answer the questions. If question is not related to the portfolio or you cannot answer the question, say, 'contact a representative for more assistance.'\"\n",
    "    + \"If the user asks for help or says 'help', provide a list of sample questions that you can answer.\",\n",
    "    tools=tools_list,\n",
    "    model=api_deployment_name,\n",
    "    file_ids=file_ids,\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_functions(client: AzureOpenAI, thread: Thread, run: Run) -> None:\n",
    "    print(\"Function Calling\")\n",
    "    required_actions = run.required_action.submit_tool_outputs.model_dump()\n",
    "    print(required_actions)\n",
    "    tool_outputs = []\n",
    "    import json\n",
    "\n",
    "    for action in required_actions[\"tool_calls\"]:\n",
    "        func_name = action[\"function\"][\"name\"]\n",
    "        arguments = json.loads(action[\"function\"][\"arguments\"])\n",
    "\n",
    "        if func_name == \"get_stock_price\":\n",
    "            output = get_stock_price(symbol=arguments[\"symbol\"])\n",
    "            tool_outputs.append({\"tool_call_id\": action[\"id\"], \"output\": output})\n",
    "        elif func_name == \"send_email\":\n",
    "            print(\"Sending email...\")\n",
    "            email_to = arguments[\"to\"]\n",
    "            email_content = arguments[\"content\"]\n",
    "            send_logic_apps_email(email_to, email_content)\n",
    "\n",
    "            tool_outputs.append({\"tool_call_id\": action[\"id\"], \"output\": \"Email sent\"})\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown function: {func_name}\")\n",
    "\n",
    "    print(\"Submitting outputs back to the Assistant...\")\n",
    "    client.beta.threads.runs.submit_tool_outputs(thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and display the Assistant Messages for text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_assistant_file(file_id:str):\n",
    "    response_content = client.files.content(file_id)\n",
    "    return response_content.read()\n",
    "\n",
    "def print_messages(messages: Iterable[MessageFile]) -> None:\n",
    "    message_list = []\n",
    "\n",
    "    # Get all the messages till the last user message\n",
    "    for message in messages:\n",
    "        message_list.append(message)\n",
    "        if message.role == \"user\":\n",
    "            break\n",
    "\n",
    "    # Reverse the messages to show the last user message first\n",
    "    message_list.reverse()\n",
    "\n",
    "    # Print the user or Assistant messages or images\n",
    "    for message in message_list:\n",
    "        for item in message.content:\n",
    "            # Determine the content type\n",
    "            if isinstance(item, TextContentBlock):\n",
    "                print(f\"{message.role}:\\n{item.text.value}\\n\")\n",
    "                file_annotations = item.text.annotations\n",
    "                if file_annotations:\n",
    "                    for annotation in file_annotations:\n",
    "                        file_id = annotation.file_path.file_id\n",
    "                        content = read_assistant_file(file_id)\n",
    "                        print(f\"Annotation Content:\\n{str(content)}\\n\")\n",
    "            elif isinstance(item, ImageFileContentBlock):\n",
    "                # Retrieve image from file id                \n",
    "                data_in_bytes = read_assistant_file(item.image_file.file_id)\n",
    "                # Convert bytes to image\n",
    "                readable_buffer = io.BytesIO(data_in_bytes)\n",
    "                image = Image.open(readable_buffer)\n",
    "                # Resize image to fit in terminal\n",
    "                width, height = image.size\n",
    "                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n",
    "                # Display image\n",
    "                image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(prompt: str) -> None:\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions=\"Please address the user as Jane Doe. The user has a premium account. Be assertive, accurate, and polite. Ask if the user has further questions. \"\n",
    "        + \"The current date and time is: \"\n",
    "        + datetime.now().strftime(\"%x %X\")\n",
    "        + \". \",\n",
    "    )\n",
    "    print(\"processing ...\")\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run.status == \"completed\":\n",
    "            # Handle completed\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            print_messages(messages)\n",
    "            break\n",
    "        if run.status == \"failed\":\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            answer = messages.data[0].content[0].text.value\n",
    "            print(f\"Failed User:\\n{prompt}\\nAssistant:\\n{answer}\\n\")\n",
    "            # Handle failed\n",
    "            break\n",
    "        if run.status == \"expired\":\n",
    "            # Handle expired\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"cancelled\":\n",
    "            # Handle cancelled\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"requires_action\":\n",
    "            call_functions(client, thread, run)\n",
    "        else:\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a conversation with the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Based on the provided portfolio, what investments do I own?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"What is the value of my portfolio?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"What is my best and worst investment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Chart the realized gain or loss of my investments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\n",
    "    \"Please send a report to name@contoso.com with the details for each stock based on the latest stock prices, and list the best and worst performing stocks in my portfolio.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    client.beta.assistants.delete(assistant.id)\n",
    "    client.beta.threads.delete(thread.id)\n",
    "    for file in assistant_files:\n",
    "        client.files.delete(file.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
